<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Weilin Cong</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Weilin Cong</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publication</a></div>
<div class="menu-item"><a href="activities.html">Activities</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Weilin Cong (‰∏õÁÇúÈúñ)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://CongWeilin.github.io/"><img src="weilin.jpg" alt="alt text" width="200px" height="200px" /></a>&nbsp;</td>
<td align="left"><p>PhD, <a href="http://www.psu.edu/">The Pennsylvania State University</a><br />
E-mail: congweilin95@gmail.com / weilin@psu.edu</p>
</td></tr></table>
<h2>About me</h2>
<p>I am a 3rd year Ph.D. candidate (since Fall 2019) of <a href="https://www.eecs.psu.edu/">Computer Science and Engineering</a> at <a href="http://www.psu.edu/">The Pennsylvania State University</a>,
under the supervision of Prof. <a href="http://www.cse.psu.edu/~mzm616/">Mehrdad Mahdavi</a>. 
I received my B.S. degree from <a href="http://english.bit.edu.cn/">Beijing institute of Technology</a>.</p>

Besides, my last name Cong (simplified ‰∏õ / traditional Âè¢) is pronounced as <a href="https://www.youtube.com/watch?v=HcZoiKLGu4I&ab_channel=Hied">ts-oh-ng</a> in Pinyin üßê

<h2>Research Interests</h2>

My research focuses on both the fundamental problems in graph representation learning (including optimization, generalization, and expressive power) and model architecture design:
<ul>
  <li><p> Optimization: scaling graph neural network training by sampling, distributed graph neural network training, and efficient graph representation unlearning for privacy; </p></li>
  <li><p> Generalization and expressive power: understanding why GNN suffer from performance degradation when the depth go deeper; </p></li>
  <li><p> Model architecture design: design a Graph Transformer network that can efficiently solve the dynamic graph reasoning problem. </p></li>
</ul>
Please refer to the publications for more details.


<h2>Most recent update (05/26/2022)</h2>
Our most recent work on <b>graph representation unlearning</b> is available online, in which our goal is to efficiently remove the effect of a node/edge on the pre-trained GNN model.
<ul>
  <li> <p> In <a href="files/GraphEditor.pdf">GraphEditor</a>, we first formulate GNNs as an alternative problem with closed-form solution, then we can edit the weight parameters based on the change of graph structure. </p> </li> <img src="files/which_node_get_affected_combined.jpg" alt="right" width="466px" height="200px" />
  <li> <p> In <a href="files/Projector.pdf">Projector</a>, based on our observation that the linear GNN trained with logistic regression is in the linear span of all node features, we propose a projection-based unlearning approach that project the original weight paramters into a subspace that is irrelevant to the deleted node features.</p> </li> <img src="files/orthogonal_proj_weight.jpg" alt="right" width="388px" height="200px" />
</ul>
A short video presentation on a high-level introduction of our works will be released soon.

<h2>Working Experience</h2>
<ul>
  <li>
    <p>Meta AI Research, Menlo Park, CA</p>
    <p>Research intern, May.2022 - Aug.2022</p> 
    <p>Supervisor: <a href="https://sizhang2.web.illinois.edu/">Si Zhang</a> </p>
    <p>Topic: Dynamic graph reasoning using Transformers </p>
  </li>
  
  <li>
  <p>Meta AI Research, Remote, US</p>
  <p>Research intern, Jun.2021 - Aug.2021</p> 
  <p>Supervisor: <a href="http://yhwu.me/">Yanhong Wu</a> </p>
  <p>Topic: Dynamic graph reasoning using Transformers</p>
</li>
<!-- <li><p>Dynamic graph representation learning;</p></li> -->
</ul>

<!-- <h2>Honors, Awards and Grants</h2>
<ul> -->
  <!-- <li><p>NeurIPS Travel Award: 2021, 2020</p></li> -->
  <!-- <li><p>KDD Travel Award: 2020</p></li> -->
<!-- </ul> -->


<div id="footer">
<div id="footer-text">
Page last updated on 11/24/2021.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
